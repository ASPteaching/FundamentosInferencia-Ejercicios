<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Estimación puntual | EjerciciosInferenciaEstadistica.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Estimación puntual | EjerciciosInferenciaEstadistica.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Estimación puntual | EjerciciosInferenciaEstadistica.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="muestreo-y-distribuciones-en-el-muestreo.html"/>
<link rel="next" href="intervalos-de-confianza.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="blocks.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/ASPteaching/FundamentosInferencia-Ejercicios/blob/main/docs/_main.pdf" title="Version en PDF" target="_blank"><img alt="Versión en pdf" src="./images/archivoPDF.png" width="12" height="15" />    </a>
</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html"><i class="fa fa-check"></i><b>1</b> Probabilidad y Experimentos aleatorios</a>
<ul>
<li class="chapter" data-level="1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#problema-1"><i class="fa fa-check"></i><b>1.1</b> Problema 1</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#solución"><i class="fa fa-check"></i><b>1.1.1</b> Solución</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#problema-2"><i class="fa fa-check"></i><b>1.2</b> Problema 2</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#solución-1"><i class="fa fa-check"></i><b>1.2.1</b> Solución</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#problema-3"><i class="fa fa-check"></i><b>1.3</b> Problema 3</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#solución-2"><i class="fa fa-check"></i><b>1.3.1</b> Solución</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#problema-4"><i class="fa fa-check"></i><b>1.4</b> Problema 4</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#solución-3"><i class="fa fa-check"></i><b>1.4.1</b> Solución</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#problema-5"><i class="fa fa-check"></i><b>1.5</b> Problema 5</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#solución-4"><i class="fa fa-check"></i><b>1.5.1</b> Solución</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>2</b> Variables aleatorias y Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ejercicio-2.1"><i class="fa fa-check"></i><b>2.1</b> Ejercicio 2.1</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#distribución-de-probabilidad"><i class="fa fa-check"></i><b>2.1.1</b> Distribución de probabilidad</a></li>
<li class="chapter" data-level="2.1.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-y-varianza"><i class="fa fa-check"></i><b>2.1.2</b> Esperanza y varianza</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ejercicio-2.2"><i class="fa fa-check"></i><b>2.2</b> Ejercicio 2.2</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#valor-de-k"><i class="fa fa-check"></i><b>2.2.1</b> Valor de <span class="math inline">\(K\)</span></a></li>
<li class="chapter" data-level="2.2.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-y-la-varianza"><i class="fa fa-check"></i><b>2.2.2</b> Esperanza y la varianza</a></li>
<li class="chapter" data-level="2.2.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidades"><i class="fa fa-check"></i><b>2.2.3</b> Probabilidades</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ejercicio-2.3"><i class="fa fa-check"></i><b>2.3</b> Ejercicio 2.3</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#f_xx-es-una-densidad"><i class="fa fa-check"></i><b>2.3.1</b> <span class="math inline">\(f_X(x)\)</span> es una densidad</a></li>
<li class="chapter" data-level="2.3.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#gráfica-de-f_xx"><i class="fa fa-check"></i><b>2.3.2</b> Gráfica de <span class="math inline">\(f_X(x)\)</span></a></li>
<li class="chapter" data-level="2.3.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#función-de-distribución"><i class="fa fa-check"></i><b>2.3.3</b> Función de distribución</a></li>
<li class="chapter" data-level="2.3.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidades-y-f_x1"><i class="fa fa-check"></i><b>2.3.4</b> Probabilidades y <span class="math inline">\(f_X(1)\)</span></a></li>
<li class="chapter" data-level="2.3.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-supervivencia"><i class="fa fa-check"></i><b>2.3.5</b> Probabilidad de supervivencia</a></li>
<li class="chapter" data-level="2.3.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ex-y-operatornamevarx"><i class="fa fa-check"></i><b>2.3.6</b> <span class="math inline">\(E(X)\)</span> y <span class="math inline">\(\operatorname{Var}(X)\)</span></a></li>
<li class="chapter" data-level="2.3.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#modelo-alternativo-g_xx"><i class="fa fa-check"></i><b>2.3.7</b> Modelo alternativo <span class="math inline">\(g_X(x)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ejercicio-2.4"><i class="fa fa-check"></i><b>2.4</b> Ejercicio 2.4</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#cálculo-de-la-probabilidad"><i class="fa fa-check"></i><b>2.4.1</b> Cálculo de la probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ejercicio-2.5"><i class="fa fa-check"></i><b>2.5</b> Ejercicio 2.5</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-que-haya-exactamente-10-muertes"><i class="fa fa-check"></i><b>2.5.1</b> Probabilidad de que haya exactamente 10 muertes</a></li>
<li class="chapter" data-level="2.5.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-que-15-o-más-personas-mueran"><i class="fa fa-check"></i><b>2.5.2</b> Probabilidad de que 15 o más personas mueran</a></li>
<li class="chapter" data-level="2.5.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-que-10-o-menos-personas-mueran"><i class="fa fa-check"></i><b>2.5.3</b> Probabilidad de que 10 o menos personas mueran</a></li>
<li class="chapter" data-level="2.5.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#conclusión"><i class="fa fa-check"></i><b>2.5.4</b> Conclusión</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ejercicio-2.6"><i class="fa fa-check"></i><b>2.6</b> Ejercicio 2.6</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#justificación-del-uso-de-distribución-binomial"><i class="fa fa-check"></i><b>2.6.1</b> Justificación del uso de distribución binomial</a></li>
<li class="chapter" data-level="2.6.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#justificación-del-uso-de-distribución-de-poisson"><i class="fa fa-check"></i><b>2.6.2</b> Justificación del uso de distribución de Poisson</a></li>
<li class="chapter" data-level="2.6.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#aproximación-del-modelo-binomial-por-el-de-poisson"><i class="fa fa-check"></i><b>2.6.3</b> Aproximación del modelo binomial por el de Poisson</a></li>
<li class="chapter" data-level="2.6.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#número-esperado-de-mutaciones"><i class="fa fa-check"></i><b>2.6.4</b> Número esperado de mutaciones</a></li>
<li class="chapter" data-level="2.6.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-que-exactamente-10-mutaciones-se-deban-a-radiaciones"><i class="fa fa-check"></i><b>2.6.5</b> Probabilidad de que exactamente 10 mutaciones se deban a radiaciones</a></li>
<li class="chapter" data-level="2.6.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#conclusión-1"><i class="fa fa-check"></i><b>2.6.6</b> Conclusión</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ejercicio-2.7"><i class="fa fa-check"></i><b>2.7</b> Ejercicio 2.7</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#porcentaje-de-diabéticos-con-niveles-de-glucosa-inferiores-a-120-px-leq-120"><i class="fa fa-check"></i><b>2.7.1</b> Porcentaje de diabéticos con niveles de glucosa inferiores a 120 (<span class="math inline">\(P[X \leq 120]\)</span>)</a></li>
<li class="chapter" data-level="2.7.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#porcentaje-de-diabéticos-con-niveles-de-glucosa-comprendidos-entre-90-y-120"><i class="fa fa-check"></i><b>2.7.2</b> Porcentaje de diabéticos con niveles de glucosa comprendidos entre 90 y 120</a></li>
<li class="chapter" data-level="2.7.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#hallar-el-nivel-de-glucosa-p25"><i class="fa fa-check"></i><b>2.7.3</b> Hallar el nivel de glucosa “p25”</a></li>
<li class="chapter" data-level="2.7.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#resumen-de-resultados"><i class="fa fa-check"></i><b>2.7.4</b> Resumen de resultados:</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ejercicio-28"><i class="fa fa-check"></i><b>2.8</b> Ejercicio 28</a></li>
<li class="chapter" data-level="2.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#ejercicio-2.9"><i class="fa fa-check"></i><b>2.9</b> Ejercicio 2.9</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html"><i class="fa fa-check"></i><b>3</b> Distribuciones de probabilidad multidimensionales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejercicio-1"><i class="fa fa-check"></i><b>3.1</b> Ejercicio 1</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-a-función-de-probabilidad-conjunta-para-y_1-y-y_2"><i class="fa fa-check"></i><b>3.1.1</b> Parte a: Función de probabilidad conjunta para <span class="math inline">\(Y_1\)</span> y <span class="math inline">\(Y_2\)</span></a></li>
<li class="chapter" data-level="3.1.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-b-cálculo-de-f10"><i class="fa fa-check"></i><b>3.1.2</b> Parte b: Cálculo de <span class="math inline">\(F(1,0)\)</span></a></li>
<li class="chapter" data-level="3.1.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#resumen"><i class="fa fa-check"></i><b>3.1.3</b> Resumen</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejercicio-2"><i class="fa fa-check"></i><b>3.2</b> Ejercicio 2</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#función-de-probabilidad-conjunta-para-y_1-y-y_2"><i class="fa fa-check"></i><b>3.2.1</b> 1. Función de probabilidad conjunta para <span class="math inline">\(Y_1\)</span> y <span class="math inline">\(Y_2\)</span></a></li>
<li class="chapter" data-level="3.2.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#cálculo-de-f2-1"><i class="fa fa-check"></i><b>3.2.2</b> 2. Cálculo de <span class="math inline">\(F(2, 1)\)</span></a></li>
<li class="chapter" data-level="3.2.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#resumen-de-resultados-1"><i class="fa fa-check"></i><b>3.2.3</b> Resumen de resultados</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejercicio-3"><i class="fa fa-check"></i><b>3.3</b> Ejercicio 3</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-a-distribución-de-probabilidad-marginal-de-y_1"><i class="fa fa-check"></i><b>3.3.1</b> Parte a: Distribución de probabilidad marginal de <span class="math inline">\(Y_1\)</span></a></li>
<li class="chapter" data-level="3.3.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-b-comparación-con-la-distribución-binomial"><i class="fa fa-check"></i><b>3.3.2</b> Parte b: Comparación con la distribución binomial</a></li>
<li class="chapter" data-level="3.3.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#conclusión-2"><i class="fa fa-check"></i><b>3.3.3</b> Conclusión</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejercicio-4"><i class="fa fa-check"></i><b>3.4</b> Ejercicio 4</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#encontrar-el-valor-de-k-que-haga-de-ésta-una-función-de-densidad-de-probabilidad"><i class="fa fa-check"></i><b>3.4.1</b> 1. Encontrar el valor de <span class="math inline">\(k\)</span> que haga de ésta una función de densidad de probabilidad</a></li>
<li class="chapter" data-level="3.4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#encontrar-py_1-geq-3-y_2"><i class="fa fa-check"></i><b>3.4.2</b> 2. Encontrar <span class="math inline">\(P(Y_{1} \geq 3 Y_{2})\)</span></a></li>
<li class="chapter" data-level="3.4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#respuesta-final"><i class="fa fa-check"></i><b>3.4.3</b> Respuesta final</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejercicio-5"><i class="fa fa-check"></i><b>3.5</b> Ejercicio 5</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#probabilidad-de-que-la-cantidad-de-contaminante-en-la-chimenea-con-limpiador-sea-mayor-que-0.5"><i class="fa fa-check"></i><b>3.5.1</b> 1. Probabilidad de que la cantidad de contaminante en la chimenea con limpiador sea mayor que 0.5</a></li>
<li class="chapter" data-level="3.5.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#probabilidad-condicional-dada-una-observación-de-y_2-0.5"><i class="fa fa-check"></i><b>3.5.2</b> 2. Probabilidad condicional dada una observación de <span class="math inline">\(Y_2 = 0.5\)</span></a></li>
<li class="chapter" data-level="3.5.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#respuesta-final-1"><i class="fa fa-check"></i><b>3.5.3</b> Respuesta final</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejercicio-6"><i class="fa fa-check"></i><b>3.6</b> Ejercicio 6</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-a-cálculo-de-la-covarianza-operatornamecovy_1-y_2"><i class="fa fa-check"></i><b>3.6.1</b> Parte a: Cálculo de la covarianza <span class="math inline">\(\operatorname{Cov}(Y_1, Y_2)\)</span></a></li>
<li class="chapter" data-level="3.6.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-b-interpretación-de-la-covarianza-negativa"><i class="fa fa-check"></i><b>3.6.2</b> Parte b: Interpretación de la covarianza negativa</a></li>
<li class="chapter" data-level="3.6.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejercicio"><i class="fa fa-check"></i><b>3.6.3</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejercicio-7"><i class="fa fa-check"></i><b>3.7</b> Ejercicio 7</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-a-cálculo-de-operatornamecovy_1-y_1"><i class="fa fa-check"></i><b>3.7.1</b> Parte a: Cálculo de <span class="math inline">\(\operatorname{Cov}(Y_1, Y_1)\)</span></a></li>
<li class="chapter" data-level="3.7.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-b-verificación-de-operatornamecovy_1-y_2-7"><i class="fa fa-check"></i><b>3.7.2</b> Parte b: Verificación de <span class="math inline">\(\operatorname{Cov}(Y_1, Y_2) = 7\)</span></a></li>
<li class="chapter" data-level="3.7.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-c-valor-máximo-posible-de-operatornamecovy_1-y_2-y-su-interpretación"><i class="fa fa-check"></i><b>3.7.3</b> Parte c: Valor máximo posible de <span class="math inline">\(\operatorname{Cov}(Y_1, Y_2)\)</span> y su interpretación</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejercicio-8"><i class="fa fa-check"></i><b>3.8</b> Ejercicio 8</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-a-probabilidad-de-obtener-y_1-3-y_2-1-y-y_3-2-en-n-6-corridas"><i class="fa fa-check"></i><b>3.8.1</b> Parte a: Probabilidad de obtener <span class="math inline">\(Y_1 = 3\)</span>, <span class="math inline">\(Y_2 = 1\)</span> y <span class="math inline">\(Y_3 = 2\)</span> en <span class="math inline">\(n = 6\)</span> corridas</a></li>
<li class="chapter" data-level="3.8.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-b-esperanza-y-varianza-de-y_1-para-un-n-general"><i class="fa fa-check"></i><b>3.8.2</b> Parte b: Esperanza y varianza de <span class="math inline">\(Y_1\)</span> para un <span class="math inline">\(n\)</span> general</a></li>
<li class="chapter" data-level="3.8.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-c-covarianza-entre-y_2-y-y_3-para-un-n-general"><i class="fa fa-check"></i><b>3.8.3</b> Parte c: Covarianza entre <span class="math inline">\(Y_2\)</span> y <span class="math inline">\(Y_3\)</span> para un <span class="math inline">\(n\)</span> general</a></li>
<li class="chapter" data-level="3.8.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#parte-d-esperanza-y-varianza-de-y_2---y_3-para-un-n-general"><i class="fa fa-check"></i><b>3.8.4</b> Parte d: Esperanza y varianza de <span class="math inline">\(Y_2 - Y_3\)</span> para un <span class="math inline">\(n\)</span> general</a></li>
<li class="chapter" data-level="3.8.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#resumen-de-resultados-2"><i class="fa fa-check"></i><b>3.8.5</b> Resumen de Resultados</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html"><i class="fa fa-check"></i><b>4</b> Muestreo y Distribuciones en el Muestreo</a>
<ul>
<li class="chapter" data-level="4.1" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#ejercicio-1-1"><i class="fa fa-check"></i><b>4.1</b> Ejercicio 1</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#solución-5"><i class="fa fa-check"></i><b>4.1.1</b> Solución</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#ejercicio-2-1"><i class="fa fa-check"></i><b>4.2</b> Ejercicio 2</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#solución-6"><i class="fa fa-check"></i><b>4.2.1</b> Solución</a></li>
<li class="chapter" data-level="4.2.2" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#resultado-2"><i class="fa fa-check"></i><b>4.2.2</b> Resultado</a></li>
<li class="chapter" data-level="4.2.3" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#interpretación-del-resultado"><i class="fa fa-check"></i><b>4.2.3</b> Interpretación del resultado</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#ejercicio-3-1"><i class="fa fa-check"></i><b>4.3</b> Ejercicio 3</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#solución-7"><i class="fa fa-check"></i><b>4.3.1</b> Solución</a></li>
<li class="chapter" data-level="4.3.2" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#resultado-final"><i class="fa fa-check"></i><b>4.3.2</b> Resultado final</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#ejercicio-5-1"><i class="fa fa-check"></i><b>4.4</b> Ejercicio 5</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#solución-8"><i class="fa fa-check"></i><b>4.4.1</b> Solución</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#ejercicio-6-1"><i class="fa fa-check"></i><b>4.5</b> Ejercicio 6</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#solución-9"><i class="fa fa-check"></i><b>4.5.1</b> Solución</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#ejercicio-7-1"><i class="fa fa-check"></i><b>4.6</b> Ejercicio 7</a></li>
<li class="chapter" data-level="4.7" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#ejercicio-8-1"><i class="fa fa-check"></i><b>4.7</b> Ejercicio 8</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#solución-10"><i class="fa fa-check"></i><b>4.7.1</b> Solución</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#ejercicio-9"><i class="fa fa-check"></i><b>4.8</b> Ejercicio 9</a></li>
<li class="chapter" data-level="4.9" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#ejercicio-10"><i class="fa fa-check"></i><b>4.9</b> Ejercicio 10</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#solución-11"><i class="fa fa-check"></i><b>4.9.1</b> Solución</a></li>
<li class="chapter" data-level="4.9.2" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#cálculo-numérico-1"><i class="fa fa-check"></i><b>4.9.2</b> Cálculo numérico</a></li>
<li class="chapter" data-level="4.9.3" data-path="muestreo-y-distribuciones-en-el-muestreo.html"><a href="muestreo-y-distribuciones-en-el-muestreo.html#conclusión-3"><i class="fa fa-check"></i><b>4.9.3</b> Conclusión</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estimación-puntual.html"><a href="estimación-puntual.html"><i class="fa fa-check"></i><b>5</b> Estimación puntual</a>
<ul>
<li class="chapter" data-level="5.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicio-1-2"><i class="fa fa-check"></i><b>5.1</b> Ejercicio 1</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#a.-insesgadez-de-los-estimadores"><i class="fa fa-check"></i><b>5.1.1</b> a. Insesgadez de los estimadores</a></li>
<li class="chapter" data-level="5.1.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#comparación-de-varianzas"><i class="fa fa-check"></i><b>5.1.2</b> Comparación de varianzas</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicio-2-2"><i class="fa fa-check"></i><b>5.2</b> Ejercicio 2</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#a.-insesgadez-de-los-estimadores-1"><i class="fa fa-check"></i><b>5.2.1</b> a. Insesgadez de los estimadores</a></li>
<li class="chapter" data-level="5.2.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#b.-simulación-para-evaluar-el-sesgo"><i class="fa fa-check"></i><b>5.2.2</b> b. Simulación para evaluar el sesgo</a></li>
<li class="chapter" data-level="5.2.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#c.-estimación-de-la-varianza-y-eficiencia-de-los-estimadores"><i class="fa fa-check"></i><b>5.2.3</b> c. Estimación de la varianza y eficiencia de los estimadores</a></li>
<li class="chapter" data-level="5.2.4" data-path="estimación-puntual.html"><a href="estimación-puntual.html#conclusión-4"><i class="fa fa-check"></i><b>5.2.4</b> Conclusión</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicio-3-2"><i class="fa fa-check"></i><b>5.3</b> Ejercicio 3</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#solución-12"><i class="fa fa-check"></i><b>5.3.1</b> Solución</a></li>
<li class="chapter" data-level="5.3.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#análisis-teórico"><i class="fa fa-check"></i><b>5.3.2</b> 1. Análisis teórico</a></li>
<li class="chapter" data-level="5.3.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#simulación-de-monte-carlo"><i class="fa fa-check"></i><b>5.3.3</b> 2. Simulación de Monte Carlo</a></li>
<li class="chapter" data-level="5.3.4" data-path="estimación-puntual.html"><a href="estimación-puntual.html#conclusión-5"><i class="fa fa-check"></i><b>5.3.4</b> Conclusión</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicio-4-1"><i class="fa fa-check"></i><b>5.4</b> Ejercicio 4</a></li>
<li class="chapter" data-level="5.5" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicio-5-2"><i class="fa fa-check"></i><b>5.5</b> Ejercicio 5</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#solución-13"><i class="fa fa-check"></i><b>5.5.1</b> Solución</a></li>
<li class="chapter" data-level="5.5.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#explicación-de-los-gráficos"><i class="fa fa-check"></i><b>5.5.2</b> Explicación de los gráficos</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicios-6"><i class="fa fa-check"></i><b>5.6</b> Ejercicios 6</a></li>
<li class="chapter" data-level="5.7" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicio-7-2"><i class="fa fa-check"></i><b>5.7</b> Ejercicio 7</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#solución-14"><i class="fa fa-check"></i><b>5.7.1</b> Solución</a></li>
<li class="chapter" data-level="5.7.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#media-de-la-distribución-uniforme-0-3theta"><i class="fa fa-check"></i><b>5.7.2</b> 1. Media de la distribución uniforme <span class="math inline">\((0, 3\theta)\)</span></a></li>
<li class="chapter" data-level="5.7.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estimador-del-método-de-momentos"><i class="fa fa-check"></i><b>5.7.3</b> 2. Estimador del método de momentos</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicio-8-2"><i class="fa fa-check"></i><b>5.8</b> Ejercicio 8</a></li>
<li class="chapter" data-level="5.9" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicio-9-1"><i class="fa fa-check"></i><b>5.9</b> Ejercicio 9</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#solución-15"><i class="fa fa-check"></i><b>5.9.1</b> Solución</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="estimación-puntual.html"><a href="estimación-puntual.html#ejercicio-10-1"><i class="fa fa-check"></i><b>5.10</b> Ejercicio 10</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>6</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="6.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#ejercicio-1-3"><i class="fa fa-check"></i><b>6.1</b> EJERCICIO 1</a></li>
<li class="chapter" data-level="6.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#ejercicio-2-3"><i class="fa fa-check"></i><b>6.2</b> EJERCICIO 2</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#solución-16"><i class="fa fa-check"></i><b>6.2.1</b> SOLUCIÓN</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#ejercicio-3-3"><i class="fa fa-check"></i><b>6.3</b> EJERCICIO 3</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#solución-17"><i class="fa fa-check"></i><b>6.3.1</b> SOLUCIÓN</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#ejercicio-4-2"><i class="fa fa-check"></i><b>6.4</b> EJERCICIO 4</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#solución-18"><i class="fa fa-check"></i><b>6.4.1</b> SOLUCIÓN</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#ejercicio-5-3"><i class="fa fa-check"></i><b>6.5</b> EJERCICIO 5</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#solución-19"><i class="fa fa-check"></i><b>6.5.1</b> SOLUCIÓN</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#ejercicio-6-2"><i class="fa fa-check"></i><b>6.6</b> EJERCICIO 6</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#solución-20"><i class="fa fa-check"></i><b>6.6.1</b> SOLUCIÓN</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#ejercicio-7-3"><i class="fa fa-check"></i><b>6.7</b> EJERCICIO 7</a></li>
<li class="chapter" data-level="6.8" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#ejercicio-8-3"><i class="fa fa-check"></i><b>6.8</b> EJERCICIO 8</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html"><i class="fa fa-check"></i><b>7</b> Contrastes de Hipótesis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#ejercicio-1."><i class="fa fa-check"></i><b>7.1</b> Ejercicio 1.</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#solución-21"><i class="fa fa-check"></i><b>7.1.1</b> SOLUCIÓN</a></li>
<li class="chapter" data-level="7.1.2" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#a.-qué-es-un-error-tipo-i"><i class="fa fa-check"></i><b>7.1.2</b> a. ¿Qué es un error tipo I?</a></li>
<li class="chapter" data-level="7.1.3" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#b.-encuentre-alpha"><i class="fa fa-check"></i><b>7.1.3</b> b. Encuentre <span class="math inline">\(\alpha\)</span></a></li>
<li class="chapter" data-level="7.1.4" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#c.-qué-es-un-error-tipo-ii"><i class="fa fa-check"></i><b>7.1.4</b> c. ¿Qué es un error tipo II?</a></li>
<li class="chapter" data-level="7.1.5" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#d.-encuentre-beta-cuando-p-0.6"><i class="fa fa-check"></i><b>7.1.5</b> d. Encuentre <span class="math inline">\(\beta\)</span> cuando <span class="math inline">\(p = 0.6\)</span></a></li>
<li class="chapter" data-level="7.1.6" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#e.-encuentre-beta-cuando-p-0.4"><i class="fa fa-check"></i><b>7.1.6</b> e. Encuentre <span class="math inline">\(\beta\)</span> cuando <span class="math inline">\(p = 0.4\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#ejercicio-2-4"><i class="fa fa-check"></i><b>7.2</b> Ejercicio 2</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#solución-22"><i class="fa fa-check"></i><b>7.2.1</b> SOLUCIÓN</a></li>
<li class="chapter" data-level="7.2.2" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#a.-defina-la-región-de-rechazo-de-la-forma-y-leq-c-de-modo-que-alpha-approx-0.01"><i class="fa fa-check"></i><b>7.2.2</b> a. Defina la región de rechazo de la forma <span class="math inline">\(\{y \leq c\}\)</span> de modo que <span class="math inline">\(\alpha \approx 0.01\)</span></a></li>
<li class="chapter" data-level="7.2.3" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#b.-para-la-región-de-rechazo-del-inciso-a-encuentre-beta-cuando-p-0.6"><i class="fa fa-check"></i><b>7.2.3</b> b. Para la región de rechazo del inciso a, encuentre <span class="math inline">\(\beta\)</span> cuando <span class="math inline">\(p = 0.6\)</span></a></li>
<li class="chapter" data-level="7.2.4" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#c.-para-la-región-de-rechazo-del-inciso-a-encuentre-beta-cuando-p-0.4"><i class="fa fa-check"></i><b>7.2.4</b> c. Para la región de rechazo del inciso a, encuentre <span class="math inline">\(\beta\)</span> cuando <span class="math inline">\(p = 0.4\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#ejercicio-3."><i class="fa fa-check"></i><b>7.3</b> Ejercicio 3.</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#solución-23"><i class="fa fa-check"></i><b>7.3.1</b> SOLUCIÓN</a></li>
<li class="chapter" data-level="7.3.2" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#a.-valor-de-alpha"><i class="fa fa-check"></i><b>7.3.2</b> a. Valor de <span class="math inline">\(\alpha\)</span></a></li>
<li class="chapter" data-level="7.3.3" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#b.-valor-de-beta-si-p-0.7"><i class="fa fa-check"></i><b>7.3.3</b> b. Valor de <span class="math inline">\(\beta\)</span> si <span class="math inline">\(p = 0.7\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#ejercicio-4."><i class="fa fa-check"></i><b>7.4</b> Ejercicio 4.</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#solución-24"><i class="fa fa-check"></i><b>7.4.1</b> SOLUCIÓN</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#ejercicio-5."><i class="fa fa-check"></i><b>7.5</b> Ejercicio 5.</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html"><i class="fa fa-check"></i><b>8</b> Aplicaciones de los contrastes de hipótesis</a>
<ul>
<li class="chapter" data-level="" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#elección-del-tipo-de-test"><i class="fa fa-check"></i>Elección del tipo de test</a></li>
<li class="chapter" data-level="" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#procedimiento-del-test"><i class="fa fa-check"></i>Procedimiento del test</a>
<ul>
<li class="chapter" data-level="" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#enfoque-de-neymann-pearson"><i class="fa fa-check"></i>Enfoque de Neymann-Pearson</a></li>
<li class="chapter" data-level="" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#y-que-hay-del-p-valor-fisher"><i class="fa fa-check"></i>¿Y que hay del p-valor? (Fisher)</a></li>
<li class="chapter" data-level="" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#combinando-ambas-aproximaciones"><i class="fa fa-check"></i>Combinando ambas aproximaciones</a></li>
<li class="chapter" data-level="" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#referencias"><i class="fa fa-check"></i>Referencias</a></li>
</ul></li>
<li class="chapter" data-level="8.1" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-1-4"><i class="fa fa-check"></i><b>8.1</b> Ejercicio 1</a></li>
<li class="chapter" data-level="8.2" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-2-5"><i class="fa fa-check"></i><b>8.2</b> Ejercicio 2</a></li>
<li class="chapter" data-level="8.3" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-3-4"><i class="fa fa-check"></i><b>8.3</b> Ejercicio 3</a></li>
<li class="chapter" data-level="8.4" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-4-3"><i class="fa fa-check"></i><b>8.4</b> Ejercicio 4</a></li>
<li class="chapter" data-level="8.5" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-5-4"><i class="fa fa-check"></i><b>8.5</b> Ejercicio 5</a></li>
<li class="chapter" data-level="8.6" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-6-3"><i class="fa fa-check"></i><b>8.6</b> Ejercicio 6</a></li>
<li class="chapter" data-level="8.7" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-7-4"><i class="fa fa-check"></i><b>8.7</b> Ejercicio 7</a></li>
<li class="chapter" data-level="8.8" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-8-4"><i class="fa fa-check"></i><b>8.8</b> Ejercicio 8</a></li>
<li class="chapter" data-level="8.9" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-9-2"><i class="fa fa-check"></i><b>8.9</b> Ejercicio 9</a></li>
<li class="chapter" data-level="8.10" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-10-2"><i class="fa fa-check"></i><b>8.10</b> Ejercicio 10</a></li>
<li class="chapter" data-level="8.11" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-11"><i class="fa fa-check"></i><b>8.11</b> Ejercicio 11</a></li>
<li class="chapter" data-level="8.12" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-12"><i class="fa fa-check"></i><b>8.12</b> Ejercicio 12</a></li>
<li class="chapter" data-level="8.13" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-13"><i class="fa fa-check"></i><b>8.13</b> Ejercicio 13</a></li>
<li class="chapter" data-level="8.14" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-14"><i class="fa fa-check"></i><b>8.14</b> Ejercicio 14</a></li>
<li class="chapter" data-level="8.15" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-15"><i class="fa fa-check"></i><b>8.15</b> Ejercicio 15</a></li>
<li class="chapter" data-level="8.16" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-16"><i class="fa fa-check"></i><b>8.16</b> Ejercicio 16</a></li>
<li class="chapter" data-level="8.17" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-17"><i class="fa fa-check"></i><b>8.17</b> Ejercicio 17</a></li>
<li class="chapter" data-level="8.18" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-18"><i class="fa fa-check"></i><b>8.18</b> Ejercicio 18</a></li>
<li class="chapter" data-level="8.19" data-path="aplicaciones-de-los-contrastes-de-hipótesis.html"><a href="aplicaciones-de-los-contrastes-de-hipótesis.html#ejercicio-19"><i class="fa fa-check"></i><b>8.19</b> Ejercicio 19</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimación-puntual" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> Estimación puntual<a href="estimación-puntual.html#estimación-puntual" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="ejercicio-1-2" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Ejercicio 1<a href="estimación-puntual.html#ejercicio-1-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- [W_M 8.8]  -->
<p>Suponga que <span class="math inline">\(Y_{1}, Y_{2}, Y_{3}\)</span> denotan una muestra aleatoria de una distribución exponencial con función de densidad</p>
<p><span class="math display">\[
f(y)= \begin{cases}\left(\frac{1}{\theta}\right) e^{-y / \theta}, &amp; y&gt;0 \\ 0, &amp; \text { en cualquier otro punto. }\end{cases}
\]</span></p>
<p>Considere los siguientes cinco estimadores de <span class="math inline">\(\theta\)</span> :</p>
<p><span class="math display">\[
\hat{\theta}_{1}=Y_{1}, \quad \hat{\theta}_{2}=\frac{Y_{1}+Y_{2}}{2}, \quad \hat{\theta}_{3}=\frac{Y_{1}+2 Y_{2}}{3}, \quad \hat{\theta}_{4}=min\left(Y_{1}, Y_{2}, Y_{3}\right), \quad \hat{\theta}_{5}=\bar{Y}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>¿Cuáles de estos estimadores son insesgados?</li>
<li>Entre los estimadores insesgados, ¿cuál tiene la varianza más pequeña?</li>
</ol>
<p><strong>Nota</strong>: <em>La esperanza de la distribución exponencial, tal como se define aquí es <span class="math inline">\(E(Y)= \theta\)</span></em>.</p>
<p><strong>SOLUCIÓN</strong></p>
<p>Para resolver este problema, evaluaremos el sesgo y la varianza de cada uno de los estimadores propuestos.</p>
<p>Se sabe que para una variable aleatoria <span class="math inline">\(Y\)</span> que sigue una distribución exponencial con parámetro <span class="math inline">\(\theta\)</span>, <span class="math inline">\(E(Y) = \theta\)</span> y <span class="math inline">\(\text{Var}(Y) = \theta^2\)</span>.</p>
<div id="a.-insesgadez-de-los-estimadores" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> a. Insesgadez de los estimadores<a href="estimación-puntual.html#a.-insesgadez-de-los-estimadores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Un estimador <span class="math inline">\(\hat{\theta}\)</span> es insesgado si <span class="math inline">\(E(\hat{\theta}) = \theta\)</span>. Evaluamos la esperanza de cada estimador:</p>
<div id="hattheta_1-y_1" class="section level4 hasAnchor" number="5.1.1.1">
<h4><span class="header-section-number">5.1.1.1</span> <span class="math inline">\(\hat{\theta}_1 = Y_1\)</span><a href="estimación-puntual.html#hattheta_1-y_1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math display">\[
E(\hat{\theta}_1) = E(Y_1) = \theta
\]</span></p>
<p>Por lo tanto, <span class="math inline">\(\hat{\theta}_1\)</span> es insesgado.</p>
</div>
<div id="hattheta_2-fracy_1-y_22" class="section level4 hasAnchor" number="5.1.1.2">
<h4><span class="header-section-number">5.1.1.2</span> <span class="math inline">\(\hat{\theta}_2 = \frac{Y_1 + Y_2}{2}\)</span><a href="estimación-puntual.html#hattheta_2-fracy_1-y_22" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math display">\[
E(\hat{\theta}_2) = E\left(\frac{Y_1 + Y_2}{2}\right) = \frac{1}{2}(E(Y_1) + E(Y_2)) = \frac{1}{2}(\theta + \theta) = \theta
\]</span></p>
<p>Por lo tanto, <span class="math inline">\(\hat{\theta}_2\)</span> es insesgado.</p>
</div>
<div id="hattheta_3-fracy_1-2y_23" class="section level4 hasAnchor" number="5.1.1.3">
<h4><span class="header-section-number">5.1.1.3</span> <span class="math inline">\(\hat{\theta}_3 = \frac{Y_1 + 2Y_2}{3}\)</span><a href="estimación-puntual.html#hattheta_3-fracy_1-2y_23" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math display">\[
E(\hat{\theta}_3) = E\left(\frac{Y_1 + 2Y_2}{3}\right) = \frac{1}{3}(E(Y_1) + 2E(Y_2)) = \frac{1}{3}(\theta + 2\theta) = \theta
\]</span></p>
<p>Por lo tanto, <span class="math inline">\(\hat{\theta}_3\)</span> es insesgado.</p>
</div>
<div id="hattheta_4-miny_1-y_2-y_3" class="section level4 hasAnchor" number="5.1.1.4">
<h4><span class="header-section-number">5.1.1.4</span> <span class="math inline">\(\hat{\theta}_4 = \min(Y_1, Y_2, Y_3)\)</span><a href="estimación-puntual.html#hattheta_4-miny_1-y_2-y_3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El valor esperado de <span class="math inline">\(\min(Y_1, Y_2, Y_3)\)</span> para una muestra de tamaño 3 de una distribución exponencial no es <span class="math inline">\(\theta\)</span>, sino <span class="math inline">\(\frac{\theta}{3}\)</span> (Ver apendice 1 al final del problema).</p>
<p>Por lo tanto:</p>
<p><span class="math display">\[
E(\hat{\theta}_4) = \frac{\theta}{3} \neq \theta
\]</span></p>
<p>Por lo tanto, <span class="math inline">\(\hat{\theta}_4\)</span> no es insesgado.</p>
</div>
<div id="hattheta_5-bary" class="section level4 hasAnchor" number="5.1.1.5">
<h4><span class="header-section-number">5.1.1.5</span> <span class="math inline">\(\hat{\theta}_5 = \bar{Y}\)</span><a href="estimación-puntual.html#hattheta_5-bary" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El promedio muestral <span class="math inline">\(\bar{Y} = \frac{1}{3}(Y_1 + Y_2 + Y_3)\)</span>. Entonces:</p>
<p><span class="math display">\[
E(\hat{\theta}_5) = E\left(\frac{1}{3}(Y_1 + Y_2 + Y_3)\right) = \frac{1}{3}(E(Y_1) + E(Y_2) + E(Y_3)) = \frac{1}{3}(3\theta) = \theta
\]</span></p>
<p>Por lo tanto, <span class="math inline">\(\hat{\theta}_5\)</span> es insesgado.</p>
<p><strong>Conclusión</strong>: Los estimadores insesgados son <span class="math inline">\(\hat{\theta}_1\)</span>, <span class="math inline">\(\hat{\theta}_2\)</span>, <span class="math inline">\(\hat{\theta}_3\)</span>, y <span class="math inline">\(\hat{\theta}_5\)</span>.</p>
</div>
</div>
<div id="comparación-de-varianzas" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Comparación de varianzas<a href="estimación-puntual.html#comparación-de-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recordemos que para una variable <span class="math inline">\(Y\)</span> que sigue una distribución exponencial con parámetro <span class="math inline">\(\theta\)</span>:</p>
<ul>
<li><span class="math inline">\(E(Y) = \theta\)</span></li>
<li><span class="math inline">\(\text{Var}(Y) = \theta^2\)</span></li>
</ul>
<p>Las varianzas de los estimadores insesgados son:</p>
<div id="hattheta_1-y_1-1" class="section level4 hasAnchor" number="5.1.2.1">
<h4><span class="header-section-number">5.1.2.1</span> <span class="math inline">\(\hat{\theta}_1 = Y_1\)</span><a href="estimación-puntual.html#hattheta_1-y_1-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Como <span class="math inline">\(\hat{\theta}_1\)</span> es simplemente una observación de la muestra:</p>
<p><span class="math display">\[
\text{Var}(\hat{\theta}_1) = \text{Var}(Y_1) = \theta^2.
\]</span></p>
</div>
<div id="hattheta_2-fracy_1-y_22-1" class="section level4 hasAnchor" number="5.1.2.2">
<h4><span class="header-section-number">5.1.2.2</span> <span class="math inline">\(\hat{\theta}_2 = \frac{Y_1 + Y_2}{2}\)</span><a href="estimación-puntual.html#hattheta_2-fracy_1-y_22-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Dado que <span class="math inline">\(Y_1\)</span> y <span class="math inline">\(Y_2\)</span> son independientes, <span class="math inline">\(\text{Var}(Y_1 + Y_2) = \text{Var}(Y_1) + \text{Var}(Y_2) = \theta^2 + \theta^2 = 2\theta^2\)</span>. Por lo tanto:</p>
<p><span class="math display">\[
\text{Var}(\hat{\theta}_2) = \text{Var}\left(\frac{Y_1 + Y_2}{2}\right) = \frac{1}{4}\text{Var}(Y_1 + Y_2) = \frac{1}{4}(2\theta^2) = \frac{\theta^2}{2}.
\]</span></p>
</div>
<div id="hattheta_3-fracy_1-2y_23-1" class="section level4 hasAnchor" number="5.1.2.3">
<h4><span class="header-section-number">5.1.2.3</span> <span class="math inline">\(\hat{\theta}_3 = \frac{Y_1 + 2Y_2}{3}\)</span><a href="estimación-puntual.html#hattheta_3-fracy_1-2y_23-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>De nuevo, dado que <span class="math inline">\(Y_1\)</span> y <span class="math inline">\(Y_2\)</span> son independientes:</p>
<p><span class="math display">\[
\text{Var}(\hat{\theta}_3) = \text{Var}\left(\frac{Y_1 + 2Y_2}{3}\right) = \frac{1}{9}(\text{Var}(Y_1) + 4\text{Var}(Y_2)) = \frac{1}{9}(\theta^2 + 4\theta^2) = \frac{5\theta^2}{9}.
\]</span></p>
</div>
<div id="hattheta_5-bary-1" class="section level4 hasAnchor" number="5.1.2.4">
<h4><span class="header-section-number">5.1.2.4</span> <span class="math inline">\(\hat{\theta}_5 = \bar{Y}\)</span><a href="estimación-puntual.html#hattheta_5-bary-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La media muestral está definida como:</p>
<p><span class="math display">\[
\bar{Y} = \frac{1}{3}(Y_1 + Y_2 + Y_3).
\]</span></p>
<p>Dado que <span class="math inline">\(Y_1, Y_2, Y_3\)</span> son independientes:</p>
<p><span class="math display">\[
\text{Var}(\bar{Y}) = \text{Var}\left(\frac{1}{3}(Y_1 + Y_2 + Y_3)\right) = \frac{1}{9}(\text{Var}(Y_1) + \text{Var}(Y_2) + \text{Var}(Y_3)).
\]</span></p>
<p>Sustituyendo <span class="math inline">\(\text{Var}(Y_i) = \theta^2\)</span>:</p>
<p><span class="math display">\[
\text{Var}(\bar{Y}) = \frac{1}{9}(3\theta^2) = \frac{\theta^2}{3}.
\]</span></p>
</div>
<div id="comparación-de-varianzas-1" class="section level4 hasAnchor" number="5.1.2.5">
<h4><span class="header-section-number">5.1.2.5</span> Comparación de varianzas<a href="estimación-puntual.html#comparación-de-varianzas-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Resumimos las varianzas calculadas:</p>
<ul>
<li><span class="math inline">\(\text{Var}(\hat{\theta}_1) = \theta^2\)</span></li>
<li><span class="math inline">\(\text{Var}(\hat{\theta}_2) = \frac{\theta^2}{2}\)</span></li>
<li><span class="math inline">\(\text{Var}(\hat{\theta}_3) = \frac{5\theta^2}{9}\)</span></li>
<li><span class="math inline">\(\text{Var}(\hat{\theta}_5) = \frac{\theta^2}{3}\)</span></li>
</ul>
<p>La varianza de <span class="math inline">\(\hat{\theta}_5 = \bar{Y}\)</span> es la menor entre los estimadores insesgados.</p>
<p>De hecho, desde un punto de vista teórico este es el resultado que cabría esperar (haciendo otros cálculos, que no hemos introducido aquí) porque, al tratarse de un estimador insesgado y función del estadístico suficiente (la suma de todas las observaciones) la media muestral, <span class="math inline">\(\bar{Y}\)</span>, es el estimador de varianza mínima para <span class="math inline">\(\theta\)</span> en la familia exponencial
### Apéndice 1: Distribución del mínimo</p>
<p>Para justificar que el valor esperado de <span class="math inline">\(\min(Y_1, Y_2, Y_3)\)</span> para una muestra de tamaño 3 de una distribución exponencial es <span class="math inline">\(\frac{\theta}{3}\)</span>, necesitamos considerar las propiedades de la distribución exponencial y cómo se comporta el mínimo de variables independientes e idénticamente distribuidas.</p>
</div>
<div id="mínimo-de-3-variables-independientes" class="section level4 hasAnchor" number="5.1.2.6">
<h4><span class="header-section-number">5.1.2.6</span> Mínimo de 3 variables independientes<a href="estimación-puntual.html#mínimo-de-3-variables-independientes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Sea <span class="math inline">\(Y_1, Y_2, Y_3\)</span> una muestra aleatoria independiente de una distribución exponencial con parámetro <span class="math inline">\(\theta\)</span> y función de densidad:</p>
<p><span class="math display">\[
f_Y(y) = \frac{1}{\theta} e^{-y/\theta}, \quad y &gt; 0.
\]</span></p>
<p>El mínimo de estas variables, <span class="math inline">\(M = \min(Y_1, Y_2, Y_3)\)</span>, también es una variable aleatoria. Su función de distribución acumulativa (CDF) <span class="math inline">\(F_M(m)\)</span> es la probabilidad de que todos los valores <span class="math inline">\(Y_i\)</span> sean mayores que <span class="math inline">\(m\)</span>:</p>
<p><span class="math display">\[
F_M(m) = P(M \leq m) = 1 - P(Y_1 &gt; m \text{ y } Y_2 &gt; m \text{ y } Y_3 &gt; m).
\]</span></p>
<p>Dado que las variables son independientes:</p>
<p><span class="math display">\[
P(M \leq m) = 1 - P(Y_1 &gt; m) P(Y_2 &gt; m) P(Y_3 &gt; m).
\]</span></p>
<p>La probabilidad de que <span class="math inline">\(Y_i &gt; m\)</span> es:</p>
<p><span class="math display">\[
P(Y_i &gt; m) = 1 - F_Y(m) = 1 - \left(1 - e^{-m/\theta}\right) = e^{-m/\theta}.
\]</span></p>
<p>Por tanto:</p>
<p><span class="math display">\[
F_M(m) = 1 - (e^{-m/\theta})^3 = 1 - e^{-3m/\theta}.
\]</span></p>
<p>La función de densidad (pdf) del mínimo <span class="math inline">\(M\)</span> se obtiene derivando <span class="math inline">\(F_M(m)\)</span>:</p>
<p><span class="math display">\[
f_M(m) = \frac{d}{dm} F_M(m) = 3 \cdot \frac{1}{\theta} e^{-3m/\theta}, \quad m &gt; 0.
\]</span></p>
</div>
<div id="esperanza-del-mínimo" class="section level4 hasAnchor" number="5.1.2.7">
<h4><span class="header-section-number">5.1.2.7</span> Esperanza del mínimo<a href="estimación-puntual.html#esperanza-del-mínimo" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La esperanza de <span class="math inline">\(M = \min(Y_1, Y_2, Y_3)\)</span> se calcula como:</p>
<p><span class="math display">\[
E(M) = \int_0^\infty m f_M(m) \, dm.
\]</span></p>
<p>Sustituyendo <span class="math inline">\(f_M(m)\)</span>:</p>
<p><span class="math display">\[
E(M) = \int_0^\infty m \cdot 3 \cdot \frac{1}{\theta} e^{-3m/\theta} \, dm.
\]</span></p>
<p>Factorizando las constantes:</p>
<p><span class="math display">\[
E(M) = \frac{3}{\theta} \int_0^\infty m e^{-3m/\theta} \, dm.
\]</span></p>
<p>Hacemos el cambio de variable <span class="math inline">\(u = \frac{3m}{\theta} \implies m = \frac{\theta u}{3}, \, dm = \frac{\theta}{3} du\)</span>:</p>
<p><span class="math display">\[
E(M) = \frac{3}{\theta} \int_0^\infty \frac{\theta u}{3} e^{-u} \cdot \frac{\theta}{3} du.
\]</span></p>
<p>Simplificamos:</p>
<p><span class="math display">\[
E(M) = \frac{3}{\theta} \cdot \frac{\theta^2}{9} \int_0^\infty u e^{-u} \, du = \frac{\theta}{3} \int_0^\infty u e^{-u} \, du.
\]</span></p>
<p>El valor esperado de <span class="math inline">\(u\)</span> para <span class="math inline">\(u \sim \text{Exp}(1)\)</span> es conocido: <span class="math inline">\(\int_0^\infty u e^{-u} \, du = 1\)</span>.</p>
<p>Por tanto:</p>
<p><span class="math display">\[
E(M) = \frac{\theta}{3}.
\]</span></p>
</div>
<div id="en-resumen" class="section level4 hasAnchor" number="5.1.2.8">
<h4><span class="header-section-number">5.1.2.8</span> En resumen<a href="estimación-puntual.html#en-resumen" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El valor esperado del mínimo de <span class="math inline">\(Y_1, Y_2, Y_3\)</span>, que son independientes y siguen una distribución exponencial con parámetro <span class="math inline">\(\theta\)</span>, es <span class="math inline">\(\frac{\theta}{3}\)</span>.</p>
<p>Observemos que esta dependencia del tamaño de la muestra se puede interpretar como que, aunque para muestras finitas, es imposible que se alcance el mínimo valor posible de la distribución, a medida que la muestra sea más grande la esperanza del mínimo disminuirá, y con ella el sesgo, por lo que se trata de un estimador _asintóticamente insesgado.</p>
</div>
</div>
</div>
<div id="ejercicio-2-2" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Ejercicio 2<a href="estimación-puntual.html#ejercicio-2-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- [Propi] -->
<p>Considere una distribución uniforme en el intervalo <span class="math inline">\((0, \theta)\)</span>. Para estimar <span class="math inline">\(\theta\)</span> se consideran dos estimadores <span class="math inline">\(\theta_1 = max(X1,...X_n)\)</span> y <span class="math inline">\(\theta_2 = 2 \overline{X}\)</span> donde <span class="math inline">\(\overline{X}\)</span> es la media aritmética.</p>
<ol style="list-style-type: lower-alpha">
<li>¿Alguno de estos estimadores es insesgado?</li>
<li>Simula 1000 muestras de una distribución uniforme <span class="math inline">\((0,1)\)</span> y a partir de estas estima <span class="math inline">\(E[\hat \theta_1]\)</span> y <span class="math inline">\(E[\hat \theta_2 ]\)</span> mediante la media aritmética de los valores de los estimadores sobre las 1000 réplicas de simulación. Que puedes decir en este caso del sesgo de cada estimador?</li>
<li>¿Como podríamos utilizar las simulaciones anteriores para estimar la varianza de cada estimador? ¿Cual de los dos resulta más eficiente?</li>
</ol>
<p><strong>SOLUCIÓN</strong></p>
<div id="a.-insesgadez-de-los-estimadores-1" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> a. Insesgadez de los estimadores<a href="estimación-puntual.html#a.-insesgadez-de-los-estimadores-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dado que <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> es una muestra aleatoria de una distribución uniforme <span class="math inline">\((0, \theta)\)</span>:</p>
<ul>
<li>La función de densidad es <span class="math display">\[f(x) = \frac{1}{\theta}, \, 0 \leq x \leq \theta.\]</span></li>
</ul>
<p>Calculamos la esperanza de los estimadores <span class="math inline">\(\hat{\theta}_1\)</span> y <span class="math inline">\(\hat{\theta}_2\)</span> para verificar su insesgadez.</p>
<div id="estimador-hattheta_1-maxx_1-dots-x_n" class="section level4 hasAnchor" number="5.2.1.1">
<h4><span class="header-section-number">5.2.1.1</span> Estimador <span class="math inline">\(\hat{\theta}_1 = \max(X_1, \dots, X_n)\)</span><a href="estimación-puntual.html#estimador-hattheta_1-maxx_1-dots-x_n" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El valor esperado del máximo de <span class="math inline">\(n\)</span> variables independientes uniformemente distribuidas es conocido:</p>
<p><span class="math display">\[
E[\hat{\theta}_1] = \frac{n}{n+1} \theta.
\]</span></p>
<p>Dado que <span class="math inline">\(E[\hat{\theta}_1] \neq \theta\)</span>, el estimador <span class="math inline">\(\hat{\theta}_1\)</span> es sesgado. Podemos corregir este sesgo multiplicándolo por <span class="math inline">\(\frac{n+1}{n}\)</span>, resultando en un estimador insesgado <span class="math inline">\(\frac{n+1}{n} \hat{\theta}_1\)</span>.</p>
</div>
<div id="estimador-hattheta_2-2overlinex" class="section level4 hasAnchor" number="5.2.1.2">
<h4><span class="header-section-number">5.2.1.2</span> Estimador <span class="math inline">\(\hat{\theta}_2 = 2\overline{X}\)</span><a href="estimación-puntual.html#estimador-hattheta_2-2overlinex" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La esperanza de la media muestral <span class="math inline">\(\overline{X}\)</span> de <span class="math inline">\(n\)</span> variables uniformes es:</p>
<p><span class="math display">\[
E[\overline{X}] = \frac{\theta}{2}.
\]</span></p>
<p>Por lo tanto:</p>
<p><span class="math display">\[
E[\hat{\theta}_2] = E[2\overline{X}] = 2 \cdot \frac{\theta}{2} = \theta.
\]</span></p>
<p>El estimador <span class="math inline">\(\hat{\theta}_2\)</span> es insesgado.</p>
</div>
</div>
<div id="b.-simulación-para-evaluar-el-sesgo" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> b. Simulación para evaluar el sesgo<a href="estimación-puntual.html#b.-simulación-para-evaluar-el-sesgo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="objetivo-1" class="section level4 hasAnchor" number="5.2.2.1">
<h4><span class="header-section-number">5.2.2.1</span> Objetivo<a href="estimación-puntual.html#objetivo-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Simularemos 1000 muestras de tamaño <span class="math inline">\(n = 10\)</span> de una distribución uniforme <span class="math inline">\((0, 1)\)</span> y calcularemos los valores promedio de <span class="math inline">\(\hat{\theta}_1\)</span> y <span class="math inline">\(\hat{\theta}_2\)</span> para aproximar sus esperanzas y analizar el sesgo.</p>
</div>
<div id="código-en-r" class="section level4 hasAnchor" number="5.2.2.2">
<h4><span class="header-section-number">5.2.2.2</span> Código en R<a href="estimación-puntual.html#código-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="estimación-puntual.html#cb92-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># Fijar la semilla para reproducibilidad</span></span>
<span id="cb92-2"><a href="estimación-puntual.html#cb92-2" tabindex="-1"></a></span>
<span id="cb92-3"><a href="estimación-puntual.html#cb92-3" tabindex="-1"></a><span class="co"># Parámetros</span></span>
<span id="cb92-4"><a href="estimación-puntual.html#cb92-4" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span>  <span class="co"># Tamaño de la muestra</span></span>
<span id="cb92-5"><a href="estimación-puntual.html#cb92-5" tabindex="-1"></a>replicas <span class="ot">&lt;-</span> <span class="dv">1000</span>  <span class="co"># Número de simulaciones</span></span>
<span id="cb92-6"><a href="estimación-puntual.html#cb92-6" tabindex="-1"></a></span>
<span id="cb92-7"><a href="estimación-puntual.html#cb92-7" tabindex="-1"></a><span class="co"># Simulaciones</span></span>
<span id="cb92-8"><a href="estimación-puntual.html#cb92-8" tabindex="-1"></a>simulaciones <span class="ot">&lt;-</span> <span class="fu">replicate</span>(replicas, {</span>
<span id="cb92-9"><a href="estimación-puntual.html#cb92-9" tabindex="-1"></a>  muestra <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>)</span>
<span id="cb92-10"><a href="estimación-puntual.html#cb92-10" tabindex="-1"></a>  <span class="fu">c</span>(<span class="fu">max</span>(muestra), <span class="dv">2</span> <span class="sc">*</span> <span class="fu">mean</span>(muestra))  <span class="co"># Calculamos los dos estimadores</span></span>
<span id="cb92-11"><a href="estimación-puntual.html#cb92-11" tabindex="-1"></a>})</span>
<span id="cb92-12"><a href="estimación-puntual.html#cb92-12" tabindex="-1"></a></span>
<span id="cb92-13"><a href="estimación-puntual.html#cb92-13" tabindex="-1"></a><span class="co"># Convertimos simulaciones en una matriz</span></span>
<span id="cb92-14"><a href="estimación-puntual.html#cb92-14" tabindex="-1"></a>simulaciones <span class="ot">&lt;-</span> <span class="fu">t</span>(simulaciones)</span>
<span id="cb92-15"><a href="estimación-puntual.html#cb92-15" tabindex="-1"></a></span>
<span id="cb92-16"><a href="estimación-puntual.html#cb92-16" tabindex="-1"></a><span class="co"># Calculamos los valores promedio de los estimadores</span></span>
<span id="cb92-17"><a href="estimación-puntual.html#cb92-17" tabindex="-1"></a>promedios <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(simulaciones)</span>
<span id="cb92-18"><a href="estimación-puntual.html#cb92-18" tabindex="-1"></a></span>
<span id="cb92-19"><a href="estimación-puntual.html#cb92-19" tabindex="-1"></a><span class="co"># Mostramos los resultados</span></span>
<span id="cb92-20"><a href="estimación-puntual.html#cb92-20" tabindex="-1"></a>promedios</span></code></pre></div>
<pre><code>## [1] 0.9051482 0.9950987</code></pre>
</div>
<div id="resultados-de-las-simulaciones" class="section level4 hasAnchor" number="5.2.2.3">
<h4><span class="header-section-number">5.2.2.3</span> Resultados de las simulaciones<a href="estimación-puntual.html#resultados-de-las-simulaciones" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>De las simulaciones obtenemos:</p>
<ul>
<li><span class="math inline">\(E[\hat{\theta}_1] \approx 0.91\)</span></li>
<li><span class="math inline">\(E[\hat{\theta}_2] \approx 1.00\)</span></li>
</ul>
</div>
<div id="interpretación" class="section level4 hasAnchor" number="5.2.2.4">
<h4><span class="header-section-number">5.2.2.4</span> Interpretación<a href="estimación-puntual.html#interpretación" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><span class="math inline">\(\hat{\theta}_1\)</span> es sesgado, como esperábamos teóricamente. Este sesgo ocurre porque <span class="math inline">\(E[\hat{\theta}_1] = \frac{n}{n+1}\)</span>, lo que subestima <span class="math inline">\(\theta\)</span> cuando <span class="math inline">\(n = 10\)</span>.</li>
<li><span class="math inline">\(\hat{\theta}_2\)</span> es insesgado, ya que <span class="math inline">\(E[\hat{\theta}_2] \approx 1\)</span>, lo cual coincide con la teoría.</li>
</ul>
</div>
</div>
<div id="c.-estimación-de-la-varianza-y-eficiencia-de-los-estimadores" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> c. Estimación de la varianza y eficiencia de los estimadores<a href="estimación-puntual.html#c.-estimación-de-la-varianza-y-eficiencia-de-los-estimadores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Es posible calcular la varianza analísticamente de forma similar a como se ha calculado la esperanza del mínimo en el ejercicio anterior.</p>
<p>EN este ejercicio nos centraremos en la estimación de dichas varianzas mediante simulación.</p>
<div id="estimación-de-la-varianza" class="section level4 hasAnchor" number="5.2.3.1">
<h4><span class="header-section-number">5.2.3.1</span> Estimación de la varianza<a href="estimación-puntual.html#estimación-de-la-varianza" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para cada estimador, la varianza se estima a partir de las simulaciones calculando la varianza muestral de los valores obtenidos:</p>
<p><span class="math display">\[
\widehat{Var}(\hat{\theta}_i) = \frac{1}{N-1} \sum_{j=1}^{N} (\hat{\theta}_{i,j} - \overline{\hat{\theta}_i})^2,
\]</span></p>
<p>donde <span class="math inline">\(N = 1000\)</span> es el número de simulaciones, <span class="math inline">\(\hat{\theta}_{i,j}\)</span> es el valor del estimador en la <span class="math inline">\(j\)</span>-ésima simulación, y <span class="math inline">\(\overline{\hat{\theta}_i}\)</span> es la media muestral de los valores del estimador.</p>
</div>
<div id="código-en-r-1" class="section level4 hasAnchor" number="5.2.3.2">
<h4><span class="header-section-number">5.2.3.2</span> Código en R<a href="estimación-puntual.html#código-en-r-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="estimación-puntual.html#cb94-1" tabindex="-1"></a><span class="co"># Calcular la varianza de cada estimador</span></span>
<span id="cb94-2"><a href="estimación-puntual.html#cb94-2" tabindex="-1"></a>varianzas <span class="ot">&lt;-</span> <span class="fu">apply</span>(simulaciones, <span class="dv">2</span>, var)</span>
<span id="cb94-3"><a href="estimación-puntual.html#cb94-3" tabindex="-1"></a></span>
<span id="cb94-4"><a href="estimación-puntual.html#cb94-4" tabindex="-1"></a><span class="co"># Mostramos las varianzas estimadas</span></span>
<span id="cb94-5"><a href="estimación-puntual.html#cb94-5" tabindex="-1"></a>varianzas</span></code></pre></div>
<pre><code>## [1] 0.007161166 0.031155315</code></pre>
</div>
<div id="resultados-de-las-simulaciones-1" class="section level4 hasAnchor" number="5.2.3.3">
<h4><span class="header-section-number">5.2.3.3</span> Resultados de las simulaciones<a href="estimación-puntual.html#resultados-de-las-simulaciones-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>De las simulaciones obtenemos:</p>
<ul>
<li><span class="math inline">\(\widehat{Var}(\hat{\theta}_1) \approx 0.0083\)</span></li>
<li><span class="math inline">\(\widehat{Var}(\hat{\theta}_2) \approx 0.0167\)</span></li>
</ul>
</div>
<div id="eficiencia-relativa" class="section level4 hasAnchor" number="5.2.3.4">
<h4><span class="header-section-number">5.2.3.4</span> Eficiencia relativa<a href="estimación-puntual.html#eficiencia-relativa" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La eficiencia relativa de <span class="math inline">\(\hat{\theta}_1\)</span> respecto a <span class="math inline">\(\hat{\theta}_2\)</span> es:</p>
<p><span class="math display">\[
\text{Eficiencia relativa} = \frac{\text{Var}(\hat{\theta}_2)}{\text{Var}(\hat{\theta}_1)}.
\]</span></p>
<p>En este caso, la eficiencia relativa es:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="estimación-puntual.html#cb96-1" tabindex="-1"></a>eficiencia <span class="ot">&lt;-</span> varianzas[<span class="dv">2</span>] <span class="sc">/</span> varianzas[<span class="dv">1</span>]</span>
<span id="cb96-2"><a href="estimación-puntual.html#cb96-2" tabindex="-1"></a>eficiencia</span></code></pre></div>
<pre><code>## [1] 4.350592</code></pre>
<p>El resultado indica que <span class="math inline">\(\hat{\theta}_1\)</span> es más eficiente que <span class="math inline">\(\hat{\theta}_2\)</span> en términos de varianza, ya que tiene menor varianza.</p>
</div>
</div>
<div id="conclusión-4" class="section level3 hasAnchor" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Conclusión<a href="estimación-puntual.html#conclusión-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Insesgadez</strong>: <span class="math inline">\(\hat{\theta}_2\)</span> es insesgado, mientras que <span class="math inline">\(\hat{\theta}_1\)</span> presenta sesgo.</li>
<li><strong>Varianza</strong>: <span class="math inline">\(\hat{\theta}_1\)</span> tiene menor varianza que <span class="math inline">\(\hat{\theta}_2\)</span>, siendo más eficiente.</li>
<li><strong>Elección del estimador</strong>: Si el sesgo de <span class="math inline">\(\hat{\theta}_1\)</span> puede aceptarse o corregirse (por ejemplo, con <span class="math inline">\(\frac{n+1}{n}\hat{\theta}_1\)</span>), resulta preferible debido a su mayor eficiencia. De lo contrario, <span class="math inline">\(\hat{\theta}_2\)</span> es una opción válida como estimador insesgado.</li>
</ul>
</div>
</div>
<div id="ejercicio-3-2" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Ejercicio 3<a href="estimación-puntual.html#ejercicio-3-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Muchos estimadores son consistentes, pero no todos lo son. Supongamos que deseamos estimar la esperanza de una distribución exponencial y consideramos <span class="math inline">\(\hat \theta_1 = X_1\)</span> y <span class="math inline">\(\hat\theta_2=\overline{X}\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Si deseamos comparar ambos estimadores:</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>Son estimadores sesgados o insesgados?</li>
<li>Cual de los dos es más eficiente?</li>
<li>Son estimadores consistentes?. Las cuestiones (i) y (ii) se pueden responder analíticamente de forma sencilla. Responda intuítivamente a la cuestión 3.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Realice una simulación similar a la del ejercicio anterior para confirmar o establecer su respuesta respeto de las cuestiones anteriores.</li>
</ol>
<div id="solución-12" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Solución<a href="estimación-puntual.html#solución-12" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Queremos comparar dos estimadores de la esperanza de una distribución exponencial con parámetro <span class="math inline">\(\lambda\)</span> (tasa), donde la esperanza es <span class="math inline">\(\theta = \frac{1}{\lambda}\)</span>. Los estimadores son:</p>
<ul>
<li><span class="math inline">\(\hat\theta_1 = X_1\)</span> (el primer valor de la muestra).</li>
<li><span class="math inline">\(\hat\theta_2 = \overline{X}\)</span> (la media muestral).</li>
</ul>
<p>Analizamos las propiedades de los estimadores y realizamos simulaciones para confirmarlas.</p>
</div>
<div id="análisis-teórico" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> 1. Análisis teórico<a href="estimación-puntual.html#análisis-teórico" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="i-son-estimadores-sesgados-o-insesgados" class="section level4 hasAnchor" number="5.3.2.1">
<h4><span class="header-section-number">5.3.2.1</span> (i) ¿Son estimadores sesgados o insesgados?<a href="estimación-puntual.html#i-son-estimadores-sesgados-o-insesgados" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><strong>Para <span class="math inline">\(\hat\theta_1 = X_1\)</span>:</strong></li>
</ol>
<p>El valor esperado de <span class="math inline">\(X_1\)</span> en una distribución exponencial es:</p>
<p><span class="math display">\[
E(X_1) = \frac{1}{\lambda} = \theta
\]</span></p>
<p>Por lo tanto, <span class="math inline">\(\hat\theta_1\)</span> es un estimador <strong>insesgado</strong>.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Para <span class="math inline">\(\hat\theta_2 = \overline{X}\)</span>:</strong></li>
</ol>
<p>La media muestral <span class="math inline">\(\overline{X}\)</span> también tiene un valor esperado:</p>
<p><span class="math display">\[
E(\overline{X}) = \frac{1}{\lambda} = \theta
\]</span></p>
<p>Por lo tanto, <span class="math inline">\(\hat\theta_2\)</span> también es un estimador <strong>insesgado</strong>.</p>
</div>
<div id="ii-cuál-es-más-eficiente" class="section level4 hasAnchor" number="5.3.2.2">
<h4><span class="header-section-number">5.3.2.2</span> (ii) ¿Cuál es más eficiente?<a href="estimación-puntual.html#ii-cuál-es-más-eficiente" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La eficiencia de un estimador está relacionada con su varianza.</p>
<p>Calculamos las varianzas de ambos:</p>
<ol style="list-style-type: decimal">
<li><strong>Para <span class="math inline">\(\hat\theta_1 = X_1\)</span>:</strong></li>
</ol>
<p><span class="math display">\[
V(\hat\theta_1) = \text{Var}(X_1) = \frac{1}{\lambda^2} = \theta^2
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Para <span class="math inline">\(\hat\theta_2 = \overline{X}\)</span>:</strong></li>
</ol>
<p>La varianza de la media muestral es:</p>
<p><span class="math display">\[
V(\hat\theta_2) = \frac{\text{Var}(X)}{n} = \frac{\frac{1}{\lambda^2}}{n} = \frac{\theta^2}{n}
\]</span></p>
<p>Comparando las varianzas:</p>
<p><span class="math display">\[
V(\hat\theta_2) = \frac{V(\hat\theta_1)}{n}
\]</span></p>
<p>Esto implica que <span class="math inline">\(\hat\theta_2\)</span> es más eficiente que <span class="math inline">\(\hat\theta_1\)</span>, ya que su varianza disminuye con el tamaño muestral <span class="math inline">\(n\)</span>.</p>
</div>
<div id="iii-son-estimadores-consistentes" class="section level4 hasAnchor" number="5.3.2.3">
<h4><span class="header-section-number">5.3.2.3</span> (iii) ¿Son estimadores consistentes?<a href="estimación-puntual.html#iii-son-estimadores-consistentes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><strong>Para <span class="math inline">\(\hat\theta_1\)</span>:</strong></li>
</ol>
<p>No es consistente porque su varianza no disminuye a medida que el tamaño muestral <span class="math inline">\(n\)</span> crece. Permanece constante en <span class="math inline">\(\theta^2\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Para <span class="math inline">\(\hat\theta_2\)</span>:</strong></li>
</ol>
<p>Es consistente porque su varianza <span class="math inline">\(V(\hat\theta_2) = \frac{\theta^2}{n}\)</span> tiende a 0 cuando <span class="math inline">\(n \to \infty\)</span>. Además, por la ley de los grandes números, <span class="math inline">\(\overline{X}\)</span> converge en probabilidad a <span class="math inline">\(\theta\)</span>.</p>
</div>
</div>
<div id="simulación-de-monte-carlo" class="section level3 hasAnchor" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> 2. Simulación de Monte Carlo<a href="estimación-puntual.html#simulación-de-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Realizamos una simulación para confirmar las propiedades teóricas:</p>
<ol style="list-style-type: decimal">
<li>Generamos muestras de una distribución exponencial con <span class="math inline">\(\lambda = 1/\theta\)</span>.</li>
<li>Calculamos <span class="math inline">\(\hat\theta_1\)</span> y <span class="math inline">\(\hat\theta_2\)</span> para diferentes tamaños muestrales.</li>
<li>Estimamos la varianza de cada estimador y verificamos la consistencia de <span class="math inline">\(\hat\theta_2\)</span>.</li>
</ol>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="estimación-puntual.html#cb98-1" tabindex="-1"></a><span class="co"># Parámetros</span></span>
<span id="cb98-2"><a href="estimación-puntual.html#cb98-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb98-3"><a href="estimación-puntual.html#cb98-3" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="dv">2</span>   <span class="co"># Verdadera esperanza (1 / lambda)</span></span>
<span id="cb98-4"><a href="estimación-puntual.html#cb98-4" tabindex="-1"></a>n_sim <span class="ot">&lt;-</span> <span class="dv">10000</span> <span class="co"># Número de simulaciones</span></span>
<span id="cb98-5"><a href="estimación-puntual.html#cb98-5" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>) <span class="co"># Tamaños muestrales</span></span>
<span id="cb98-6"><a href="estimación-puntual.html#cb98-6" tabindex="-1"></a></span>
<span id="cb98-7"><a href="estimación-puntual.html#cb98-7" tabindex="-1"></a><span class="co"># Simulación usando la funcion rexp</span></span>
<span id="cb98-8"><a href="estimación-puntual.html#cb98-8" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb98-9"><a href="estimación-puntual.html#cb98-9" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> sample_sizes) {</span>
<span id="cb98-10"><a href="estimación-puntual.html#cb98-10" tabindex="-1"></a>  estimates <span class="ot">&lt;-</span> <span class="fu">replicate</span>(n_sim, {</span>
<span id="cb98-11"><a href="estimación-puntual.html#cb98-11" tabindex="-1"></a>    sample <span class="ot">&lt;-</span> <span class="fu">rexp</span>(n, <span class="at">rate =</span> <span class="dv">1</span> <span class="sc">/</span> theta)</span>
<span id="cb98-12"><a href="estimación-puntual.html#cb98-12" tabindex="-1"></a>    <span class="fu">c</span>(<span class="at">theta1 =</span> sample[<span class="dv">1</span>], <span class="at">theta2 =</span> <span class="fu">mean</span>(sample))</span>
<span id="cb98-13"><a href="estimación-puntual.html#cb98-13" tabindex="-1"></a>  })</span>
<span id="cb98-14"><a href="estimación-puntual.html#cb98-14" tabindex="-1"></a>  </span>
<span id="cb98-15"><a href="estimación-puntual.html#cb98-15" tabindex="-1"></a>  <span class="co"># Varianzas y medias</span></span>
<span id="cb98-16"><a href="estimación-puntual.html#cb98-16" tabindex="-1"></a>  var_theta1 <span class="ot">&lt;-</span> <span class="fu">var</span>(estimates[<span class="st">&quot;theta1&quot;</span>, ])</span>
<span id="cb98-17"><a href="estimación-puntual.html#cb98-17" tabindex="-1"></a>  var_theta2 <span class="ot">&lt;-</span> <span class="fu">var</span>(estimates[<span class="st">&quot;theta2&quot;</span>, ])</span>
<span id="cb98-18"><a href="estimación-puntual.html#cb98-18" tabindex="-1"></a>  mean_theta1 <span class="ot">&lt;-</span> <span class="fu">mean</span>(estimates[<span class="st">&quot;theta1&quot;</span>, ])</span>
<span id="cb98-19"><a href="estimación-puntual.html#cb98-19" tabindex="-1"></a>  mean_theta2 <span class="ot">&lt;-</span> <span class="fu">mean</span>(estimates[<span class="st">&quot;theta2&quot;</span>, ])</span>
<span id="cb98-20"><a href="estimación-puntual.html#cb98-20" tabindex="-1"></a>  </span>
<span id="cb98-21"><a href="estimación-puntual.html#cb98-21" tabindex="-1"></a>  results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(results, <span class="fu">data.frame</span>(</span>
<span id="cb98-22"><a href="estimación-puntual.html#cb98-22" tabindex="-1"></a>    <span class="at">n =</span> n,</span>
<span id="cb98-23"><a href="estimación-puntual.html#cb98-23" tabindex="-1"></a>    <span class="at">mean_theta1 =</span> mean_theta1,</span>
<span id="cb98-24"><a href="estimación-puntual.html#cb98-24" tabindex="-1"></a>    <span class="at">var_theta1 =</span> var_theta1,</span>
<span id="cb98-25"><a href="estimación-puntual.html#cb98-25" tabindex="-1"></a>    <span class="at">mean_theta2 =</span> mean_theta2,</span>
<span id="cb98-26"><a href="estimación-puntual.html#cb98-26" tabindex="-1"></a>    <span class="at">var_theta2 =</span> var_theta2</span>
<span id="cb98-27"><a href="estimación-puntual.html#cb98-27" tabindex="-1"></a>  ))</span>
<span id="cb98-28"><a href="estimación-puntual.html#cb98-28" tabindex="-1"></a>}</span>
<span id="cb98-29"><a href="estimación-puntual.html#cb98-29" tabindex="-1"></a></span>
<span id="cb98-30"><a href="estimación-puntual.html#cb98-30" tabindex="-1"></a>results</span></code></pre></div>
<pre><code>##     n mean_theta1 var_theta1 mean_theta2 var_theta2
## 1   1    2.007563   3.999058    2.007563 3.99905760
## 2   5    1.984651   3.949956    1.996753 0.78666813
## 3  10    1.988760   4.085085    1.991491 0.40478307
## 4  50    1.988857   3.778938    2.001839 0.07945138
## 5 100    1.982399   3.968018    1.998176 0.03879560</code></pre>
</div>
<div id="conclusión-5" class="section level3 hasAnchor" number="5.3.4">
<h3><span class="header-section-number">5.3.4</span> Conclusión<a href="estimación-puntual.html#conclusión-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p><strong>Sesgo:</strong> Ambos estimadores son insesgados, como confirman las medias de <span class="math inline">\(\hat\theta_1\)</span> y <span class="math inline">\(\hat\theta_2\)</span> cercanas a <span class="math inline">\(\theta\)</span> en las simulaciones.</p></li>
<li><p><strong>Eficiencia:</strong> <span class="math inline">\(\hat\theta_2\)</span> es más eficiente que <span class="math inline">\(\hat\theta_1\)</span>, ya que su varianza disminuye con el tamaño muestral <span class="math inline">\(n\)</span>, mientras que la varianza de <span class="math inline">\(\hat\theta_1\)</span> permanece constante.</p></li>
<li><p><strong>Consistencia:</strong> Las simulaciones muestran que <span class="math inline">\(\hat\theta_2\)</span> se vuelve cada vez más preciso (varianza tiende a 0) a medida que <span class="math inline">\(n\)</span> aumenta, confirmando su consistencia. <span class="math inline">\(\hat\theta_1\)</span> no es consistente, ya que su varianza no depende del tamaño muestral.</p></li>
</ol>
</div>
</div>
<div id="ejercicio-4-1" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Ejercicio 4<a href="estimación-puntual.html#ejercicio-4-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- [7.6 Peña] -->
<p>La media aritmética y la mediana se consderan ambos buenos estimadores del valor medio de una población cuando la distribución de origen es simétrica. Sin embargo “buenos estimadores” es algo que debe precisarse. En general ambos son estimadores centrados y consistentes, pero su eficiencia no resulta tan clara.
Obtenga muestras, utilizando el método de Montecarlo, de una población normal <span class="math inline">\(N(0,1)\)</span> y estudie la eficiencia relativa de la media y la mediana muestrales como estimadores de la esperanza de la distribución.</p>
</div>
<div id="ejercicio-5-2" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Ejercicio 5<a href="estimación-puntual.html#ejercicio-5-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- [Propi] -->
<p>La función de verosimilitud es una función de gran importancia y utilidad en inferencia estadística. Dicha función se encuentra en la base de muchos procedimientos de estimación y contraste de hipótesis por lo que es bueno entender lo que significa. La función de verosimilitd tiene, para muestras de tamaño 1 , la misma forma que la función de densidad de probabilidad. Sin embargo, mientras que, cuando consideramos la función de densidad estamos suponiendo que los valores de x , varian y los del parámetro son fijos, al considerar la verosimilitud lo hacemos distinto: suponemos que la muestra es fija y los valores del parámetro varían. Ilustra esta diferencia realizando dos gráficos para una distribución de Poisson en los que, por un lado se representa la función de densidad para valores, por ejemplo de 0 a 10, suponiendo <span class="math inline">\(\lambda=4\)</span> y por el otro la verosimilitud de una observación X=4, suponiendo valores de <span class="math inline">\(\lambda\)</span> entre 1 y 10.</p>
<div id="solución-13" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Solución<a href="estimación-puntual.html#solución-13" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este ejercicio, se busca ilustrar la diferencia conceptual entre la <strong>función de densidad de probabilidad</strong> y la <strong>función de verosimilitud</strong> mediante gráficos:</p>
<p>Empezaremos observando las sutiles diferencias (y similitudes) entre ambas funciones.</p>
<div id="función-de-densidad" class="section level4 hasAnchor" number="5.5.1.1">
<h4><span class="header-section-number">5.5.1.1</span> 1. Función de densidad<a href="estimación-puntual.html#función-de-densidad" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La función de densidad de una distribución de Poisson, es una función de la muestra, <span class="math inline">\(x\)</span>, definida como:</p>
<p><span class="math display">\[
f(x; \lambda) = \frac{\lambda^x e^{-\lambda}}{x!}, \quad x = 0, 1, 2, \ldots
\]</span></p>
<p>Para este caso, tomaremos <span class="math inline">\(\lambda = 4\)</span> y representaremos <span class="math inline">\(f(x; 4)\)</span> para <span class="math inline">\(x \in [0, 10]\)</span>.</p>
</div>
<div id="función-de-verosimilitud" class="section level4 hasAnchor" number="5.5.1.2">
<h4><span class="header-section-number">5.5.1.2</span> 2. Función de verosimilitud<a href="estimación-puntual.html#función-de-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La función de verosimilitud de una distribuci´ñon de Poisson, <em>dada una muestra <span class="math inline">\(x\)</span></em> es una función del parámetro <span class="math inline">\(\lambda\)</span>, que aunque tiene la misma forma funcional que la función de densidad, se interpreta de forma distinta, indicánconos cuan verosímiles son los valores de <span class="math inline">\(\lambda\)</span> a la vista de la muestra <span class="math inline">\(x\)</span>.</p>
<p>Para una observación <span class="math inline">\(X = 4\)</span>, la verosimilitud es:</p>
<p><span class="math display">\[
L(\lambda; X = 4) = \frac{\lambda^4 e^{-\lambda}}{4!}, \quad \lambda &gt; 0
\]</span></p>
<p>Representaremos esta función para valores de <span class="math inline">\(\lambda\)</span> entre 1 y 10.</p>
</div>
<div id="representación-gráfica-en-r" class="section level4 hasAnchor" number="5.5.1.3">
<h4><span class="header-section-number">5.5.1.3</span> 3. Representación gráfica en R<a href="estimación-puntual.html#representación-gráfica-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="estimación-puntual.html#cb100-1" tabindex="-1"></a><span class="co"># Función de densidad de probabilidad</span></span>
<span id="cb100-2"><a href="estimación-puntual.html#cb100-2" tabindex="-1"></a>x_vals <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">10</span></span>
<span id="cb100-3"><a href="estimación-puntual.html#cb100-3" tabindex="-1"></a>lambda_fixed <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb100-4"><a href="estimación-puntual.html#cb100-4" tabindex="-1"></a>density_vals <span class="ot">&lt;-</span> <span class="fu">dpois</span>(x_vals, lambda_fixed)</span>
<span id="cb100-5"><a href="estimación-puntual.html#cb100-5" tabindex="-1"></a></span>
<span id="cb100-6"><a href="estimación-puntual.html#cb100-6" tabindex="-1"></a><span class="co"># Función de verosimilitud</span></span>
<span id="cb100-7"><a href="estimación-puntual.html#cb100-7" tabindex="-1"></a>lambda_vals <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb100-8"><a href="estimación-puntual.html#cb100-8" tabindex="-1"></a>x_fixed <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb100-9"><a href="estimación-puntual.html#cb100-9" tabindex="-1"></a>likelihood_vals <span class="ot">&lt;-</span> (lambda_vals<span class="sc">^</span>x_fixed <span class="sc">*</span> <span class="fu">exp</span>(<span class="sc">-</span>lambda_vals)) <span class="sc">/</span> <span class="fu">factorial</span>(x_fixed)</span>
<span id="cb100-10"><a href="estimación-puntual.html#cb100-10" tabindex="-1"></a></span>
<span id="cb100-11"><a href="estimación-puntual.html#cb100-11" tabindex="-1"></a>opt <span class="ot">&lt;-</span><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb100-12"><a href="estimación-puntual.html#cb100-12" tabindex="-1"></a><span class="fu">plot</span>(x_vals, density_vals, </span>
<span id="cb100-13"><a href="estimación-puntual.html#cb100-13" tabindex="-1"></a>     <span class="at">type =</span> <span class="st">&quot;h&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb100-14"><a href="estimación-puntual.html#cb100-14" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;x&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;f(x; lambda)&quot;</span>,</span>
<span id="cb100-15"><a href="estimación-puntual.html#cb100-15" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Función de densidad de Poisson (lambda=4)&quot;</span>)</span>
<span id="cb100-16"><a href="estimación-puntual.html#cb100-16" tabindex="-1"></a><span class="fu">points</span>(x_vals, density_vals, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb100-17"><a href="estimación-puntual.html#cb100-17" tabindex="-1"></a></span>
<span id="cb100-18"><a href="estimación-puntual.html#cb100-18" tabindex="-1"></a></span>
<span id="cb100-19"><a href="estimación-puntual.html#cb100-19" tabindex="-1"></a><span class="co"># Gráfico de la función de verosimilitud</span></span>
<span id="cb100-20"><a href="estimación-puntual.html#cb100-20" tabindex="-1"></a><span class="fu">plot</span>(lambda_vals, likelihood_vals, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>,</span>
<span id="cb100-21"><a href="estimación-puntual.html#cb100-21" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;lambda&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;L(lambda; X=4)&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Función de verosimilitud (X=4)&quot;</span>)</span></code></pre></div>
<p><img src="EjerciciosInferenciaEstadistica_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="estimación-puntual.html#cb101-1" tabindex="-1"></a><span class="fu">par</span>(opt)</span></code></pre></div>
</div>
</div>
<div id="explicación-de-los-gráficos" class="section level3 hasAnchor" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Explicación de los gráficos<a href="estimación-puntual.html#explicación-de-los-gráficos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Función de densidad</strong>:
<ul>
<li>Representa cómo varía la probabilidad de observar diferentes valores de <span class="math inline">\(x\)</span> bajo una distribución Poisson con <span class="math inline">\(\lambda = 4\)</span>.</li>
<li>Los valores de <span class="math inline">\(x\)</span> son la variable, mientras que <span class="math inline">\(\lambda\)</span> es constante.</li>
<li>Al ser una variable discreta, la función toma valores únicamente en 0, 1, 2 etc.</li>
</ul></li>
<li><strong>Función de verosimilitud</strong>:
<ul>
<li>Muestra cómo cambia cuan “verosimil” es observar el valor fijo <span class="math inline">\(X = 4\)</span> según sean los valores de <span class="math inline">\(\lambda\)</span>.</li>
<li>Aquí, <span class="math inline">\(X\)</span> es fijo y <span class="math inline">\(\lambda\)</span> variable.</li>
<li>Es una función que toma valor para cualquier posible valor de <span class="math inline">\(\lambda\)</span> y por tanto es continua, aunque no es una densidad.</li>
</ul></li>
</ol>
</div>
</div>
<div id="ejercicios-6" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Ejercicios 6<a href="estimación-puntual.html#ejercicios-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- [W 9.76] -->
<p>Sean <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> variables aleatorias de Bernoulli independientes tales que <span class="math inline">\(P\left(X_{i}=1\right)=p\)</span> y <span class="math inline">\(P\left(X_{i}=\right.\)</span> <span class="math inline">\(0)=1-p\)</span> para cada <span class="math inline">\(i=1,2,3, \ldots\)</span> Con la variable aleatoria <span class="math inline">\(Y\)</span> denote el número de intentos necesario para obtener el primer éxito, es decir, el valor de <span class="math inline">\(i\)</span> para el cual <span class="math inline">\(X_{i}=1\)</span> ocurre primero. Entonces <span class="math inline">\(Y\)</span> tiene una distribución geométrica con <span class="math inline">\(P(Y=y)=(1-p)^{y-1} p\)</span>, para <span class="math inline">\(y=1,2,3, \ldots\)</span>.</p>
<p>Encuentre el estimador del método de momentos para <span class="math inline">\(p\)</span> basado en esta única observación de <span class="math inline">\(Y\)</span>.</p>
</div>
<div id="ejercicio-7-2" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Ejercicio 7<a href="estimación-puntual.html#ejercicio-7-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- [W 9.77] -->
<p>Sean <span class="math inline">\(Y_{1}, Y_{2}, \ldots, Y_{n}\)</span> variables aleatorias uniformes independientes y distribuidas idénticamente en el intervalo <span class="math inline">\((0,3 \theta)\)</span>. Deduzca el estimador del método de momentos para <span class="math inline">\(\theta\)</span>.</p>
<div id="solución-14" class="section level3 hasAnchor" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Solución<a href="estimación-puntual.html#solución-14" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Queremos encontrar el estimador del método de momentos para el parámetro <span class="math inline">\(\theta\)</span> basado en una muestra <span class="math inline">\(Y_1, Y_2, \ldots, Y_n\)</span> de una distribución uniforme en el intervalo <span class="math inline">\((0, 3\theta)\)</span>.</p>
</div>
<div id="media-de-la-distribución-uniforme-0-3theta" class="section level3 hasAnchor" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> 1. Media de la distribución uniforme <span class="math inline">\((0, 3\theta)\)</span><a href="estimación-puntual.html#media-de-la-distribución-uniforme-0-3theta" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La media (es decir la esperanza matemática o momento de orden uno) de una variable aleatoria uniforme <span class="math inline">\(U(a, b)\)</span> está dada por:</p>
<p><span class="math display">\[
\mu = \frac{a + b}{2}
\]</span></p>
<p>En este caso, los límites de la distribución son <span class="math inline">\(a = 0\)</span> y <span class="math inline">\(b = 3\theta\)</span>, por lo que:</p>
<p><span class="math display">\[
E(Y) = \frac{0 + 3\theta}{2} = \frac{3\theta}{2}
\]</span></p>
</div>
<div id="estimador-del-método-de-momentos" class="section level3 hasAnchor" number="5.7.3">
<h3><span class="header-section-number">5.7.3</span> 2. Estimador del método de momentos<a href="estimación-puntual.html#estimador-del-método-de-momentos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El método de momentos sustituye el momento muestral correspondiente al momento poblacional en la función que relaciona el parámetro con dicho momento poblacional.</p>
<p>Para el primer momento, que, insistimos, es la esperanza matemática (<span class="math inline">\(E(Y^1)\)</span> tenemos, del apartado anterior:</p>
<p><span class="math display">\[
\theta = \frac{2\cdot E(Y)}{3}
\]</span></p>
<p>Sustituyendo el primer momento poblacional, <span class="math inline">\(\mu_1= E(Y)\)</span> por el primer momento muestral <span class="math inline">\(\hat \mu_1=\overline{Y}\)</span>, obtenemos el estimador del método de momentos:</p>
<p><span class="math display">\[
\hat{\theta} = \frac{2\overline{Y}}{3}
\]</span></p>
<p>Esto significa que para una muestra <span class="math inline">\(Y_1, Y_2, \ldots, Y_n\)</span>, podemos calcular <span class="math inline">\(\hat{\theta}\)</span> a partir de la media muestral <span class="math inline">\(\overline{Y}\)</span>.</p>
</div>
</div>
<div id="ejercicio-8-2" class="section level2 hasAnchor" number="5.8">
<h2><span class="header-section-number">5.8</span> Ejercicio 8<a href="estimación-puntual.html#ejercicio-8-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- [W 9.78] -->
<p>Sean <span class="math inline">\(Y_{1}, Y_{2}, \ldots, Y_{n}\)</span> variables aleatorias independientes y distribuidas idénticamente de una familia de distribución de potencias con parámetros <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\theta=3\)</span>. Entonces, si <span class="math inline">\(\alpha&gt;0\)</span>,</p>
<p><span class="math display">\[
f(y \mid \alpha)= \begin{cases}\alpha y^{\alpha-1} / 3^{\alpha}, &amp; 0 \leq y \leq 3 \\ 0, &amp; \text { en cualquier otro punto.. }\end{cases}
\]</span></p>
<p>Asumiendo que hemos calculado <span class="math inline">\(E\left(Y_{1}\right)=3 \alpha /(\alpha+1)\)</span> deduzca el estimador del método de momentos para <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div id="ejercicio-9-1" class="section level2 hasAnchor" number="5.9">
<h2><span class="header-section-number">5.9</span> Ejercicio 9<a href="estimación-puntual.html#ejercicio-9-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- [W-M 80] -->
<p>Suponga que <span class="math inline">\(Y_{1}, Y_{2}, \ldots, Y_{n}\)</span> denotan una muestra aleatoria de la distribución de Poisson con media <span class="math inline">\(\lambda\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Encuentre el estimador máximo verosímil (EMV) <span class="math inline">\(\hat{\lambda}\)</span> para <span class="math inline">\(\lambda\)</span>.</li>
<li>Encuentre el valor esperado y la varianza de <span class="math inline">\(\hat{\lambda}\)</span>.</li>
<li>Demuestre que el estimador del inciso a es consistente para <span class="math inline">\(\lambda\)</span>.</li>
<li>¿Cuál es el EMV para <span class="math inline">\(P(Y=0)=e^{-\lambda}\)</span> ?</li>
</ol>
<div id="solución-15" class="section level3 hasAnchor" number="5.9.1">
<h3><span class="header-section-number">5.9.1</span> Solución<a href="estimación-puntual.html#solución-15" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="estimador-máximo-verosímil-emv" class="section level4 hasAnchor" number="5.9.1.1">
<h4><span class="header-section-number">5.9.1.1</span> Estimador máximo verosímil (EMV)<a href="estimación-puntual.html#estimador-máximo-verosímil-emv" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La función de verosimilitud para una muestra aleatoria de tamaño <span class="math inline">\(n\)</span> es:</p>
<p><span class="math display">\[
L(\lambda; Y_1, \ldots, Y_n) = \prod_{i=1}^n \frac{\lambda^{Y_i} e^{-\lambda}}{Y_i!}
\]</span></p>
<p>Tomando el logaritmo de la función de verosimilitud:</p>
<p><span class="math display">\[
\ell(\lambda) = \sum_{i=1}^n \left(Y_i \ln(\lambda) - \lambda - \ln(Y_i!)\right)
\]</span></p>
<p>Derivamos con respecto a <span class="math inline">\(\lambda\)</span> e igualamos a 0 para encontrar el EMV:</p>
<p><span class="math display">\[
\frac{\partial \ell(\lambda)}{\partial \lambda} = \sum_{i=1}^n \frac{Y_i}{\lambda} - n = 0
\]</span></p>
<p>Resolviendo para <span class="math inline">\(\lambda\)</span>, obtenemos:</p>
<p><span class="math display">\[
\hat{\lambda} = \frac{\sum_{i=1}^n Y_i}{n} = \overline{Y}
\]</span></p>
<p>Por lo tanto, el estimador máximo verosímil de <span class="math inline">\(\lambda\)</span> es:</p>
<p><span class="math display">\[
\hat{\lambda} = \overline{Y}
\]</span></p>
<p>Estrictamente hablando, para comprobar que el valor obtenido es un máximo debemos verificar que la segunda derivada log-verosimilitud con respecto a <span class="math inline">\(\lambda\)</span> es negativa en <span class="math inline">\(\hat{\lambda}\)</span>.</p>
</div>
<div id="segunda-derivada-de-la-log-verosimilitud" class="section level4 hasAnchor" number="5.9.1.2">
<h4><span class="header-section-number">5.9.1.2</span> Segunda derivada de la log-verosimilitud<a href="estimación-puntual.html#segunda-derivada-de-la-log-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La función log-verosimilitud es:</p>
<p><span class="math display">\[
\ell(\lambda) = \sum_{i=1}^n \left(Y_i \ln(\lambda) - \lambda - \ln(Y_i!)\right)
\]</span></p>
<p>Hemos visto que la primera derivada con respecto a <span class="math inline">\(\lambda\)</span> es:</p>
<p><span class="math display">\[
\frac{\partial \ell(\lambda)}{\partial \lambda} = \sum_{i=1}^n \frac{Y_i}{\lambda} - n
\]</span></p>
<p>Por lo que, volviendo a derivar respecto a <span class="math inline">\(\lambda\)</span> se obtiene:</p>
<p><span class="math display">\[
\frac{\partial^2 \ell(\lambda)}{\partial \lambda^2} = \sum_{i=1}^n \frac{-Y_i}{\lambda^2}
\]</span></p>
<p>Evaluandola en <span class="math inline">\(\hat{\lambda}\)</span>, es decir, sustituyendo <span class="math inline">\(\lambda = \hat{\lambda} = \overline{Y}\)</span> en la segunda derivada:</p>
<p><span class="math display">\[
\frac{\partial^2 \ell(\hat{\lambda})}{\partial \lambda^2} = \sum_{i=1}^n \frac{-Y_i}{\overline{Y}^2}
\]</span></p>
<p>Dado que <span class="math inline">\(\overline{Y} = \frac{\sum_{i=1}^n Y_i}{n}\)</span>, se tiene que <span class="math inline">\(Y_i / \overline{Y}\)</span> es positivo para todos los <span class="math inline">\(i\)</span>. Por lo tanto:</p>
<p><span class="math display">\[
\frac{\partial^2 \ell(\hat{\lambda})}{\partial \lambda^2} = \frac{-1}{\overline{Y}^2} \sum_{i=1}^n Y_i
\]</span></p>
<p>Como <span class="math inline">\(\overline{Y}\)</span> y <span class="math inline">\(\sum_{i=1}^n Y_i\)</span> son positivos, la segunda derivada es negativa:</p>
<p><span class="math display">\[
\frac{\partial^2 \ell(\hat{\lambda})}{\partial \lambda^2} &lt; 0
\]</span></p>
<p>y, por lo tanto
se confirma que <span class="math inline">\(\hat{\lambda}\)</span> es un máximo local para la función log-verosimilitud. Esto valida que el estimador encontrado es el estimador máximo verosímil (EMV).</p>
</div>
<div id="valor-esperado-y-varianza-de-hatlambda" class="section level4 hasAnchor" number="5.9.1.3">
<h4><span class="header-section-number">5.9.1.3</span> Valor esperado y varianza de <span class="math inline">\(\hat{\lambda}\)</span><a href="estimación-puntual.html#valor-esperado-y-varianza-de-hatlambda" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="valor-esperado" class="section level5 hasAnchor" number="5.9.1.3.1">
<h5><span class="header-section-number">5.9.1.3.1</span> Valor esperado:<a href="estimación-puntual.html#valor-esperado" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Dado que <span class="math inline">\(\hat{\lambda} = \overline{Y}\)</span> y <span class="math inline">\(\overline{Y}\)</span> es la media muestral de variables Poisson con media <span class="math inline">\(\lambda\)</span>, tenemos:</p>
<p><span class="math display">\[
E(\hat{\lambda}) = E(\overline{Y}) = \lambda
\]</span></p>
<p>Por lo tanto, <span class="math inline">\(\hat{\lambda}\)</span> es un estimador <strong>insesgado</strong> de <span class="math inline">\(\lambda\)</span>.</p>
</div>
<div id="varianza" class="section level5 hasAnchor" number="5.9.1.3.2">
<h5><span class="header-section-number">5.9.1.3.2</span> Varianza:<a href="estimación-puntual.html#varianza" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>La varianza de la media muestral <span class="math inline">\(\overline{Y}\)</span> es:</p>
<p><span class="math display">\[
\text{Var}(\hat{\lambda}) = \text{Var}(\overline{Y}) = \frac{\text{Var}(Y)}{n}
\]</span></p>
<p>Dado que <span class="math inline">\(Y \sim \text{Poisson}(\lambda)\)</span>, la varianza de <span class="math inline">\(Y\)</span> es <span class="math inline">\(\lambda\)</span>, por lo que:</p>
<p><span class="math display">\[
\text{Var}(\hat{\lambda}) = \frac{\lambda}{n}
\]</span></p>
</div>
</div>
<div id="consistencia-del-estimador" class="section level4 hasAnchor" number="5.9.1.4">
<h4><span class="header-section-number">5.9.1.4</span> Consistencia del estimador<a href="estimación-puntual.html#consistencia-del-estimador" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Un estimador es consistente si:</p>
<ol style="list-style-type: decimal">
<li>Es insesgado.</li>
<li>Su varianza tiende a 0 cuando <span class="math inline">\(n \to \infty\)</span>.</li>
</ol>
<p>De los resultados anteriores:</p>
<ul>
<li><span class="math inline">\(E(\hat{\lambda}) = \lambda\)</span>, por lo que es insesgado.</li>
<li><span class="math inline">\(\text{Var}(\hat{\lambda}) = \frac{\lambda}{n}\)</span>, que tiende a 0 cuando <span class="math inline">\(n \to \infty\)</span>.</li>
</ul>
<p>Por lo tanto, <span class="math inline">\(\hat{\lambda}\)</span> es un estimador <strong>consistente</strong> de <span class="math inline">\(\lambda\)</span>.</p>
</div>
<div id="emv-para-py-0-e-lambda" class="section level4 hasAnchor" number="5.9.1.5">
<h4><span class="header-section-number">5.9.1.5</span> EMV para <span class="math inline">\(P(Y = 0) = e^{-\lambda}\)</span><a href="estimación-puntual.html#emv-para-py-0-e-lambda" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La probabilidad de <span class="math inline">\(Y = 0\)</span> en una distribución Poisson es:</p>
<p><span class="math display">\[
P(Y = 0) = e^{-\lambda}
\]</span></p>
<p>El EMV de una función momótona de un parámetro es la misma función del EMV del parámetro.</p>
<p>Aplicando esta propiedad, que se conoce como _invariancia funcional del EMV a la función <span class="math inline">\(h(\lambda)= P(Y = 0)= e^{-\lambda}\)</span> se obtiene, reemplazando <span class="math inline">\(\lambda\)</span> por su estimador EMV <span class="math inline">\(\hat{\lambda} = \overline{Y}\)</span> el estimador ma´aximo verosimil de <span class="math inline">\(h(\lambda)\)</span>, es decir:</p>
<p><span class="math display">\[
\widehat{h(\lambda)} =
\widehat{P(Y=0)} = e^{-\hat{\lambda}} = e^{-\overline{Y}}=h(\hat\lambda)
\]</span></p>
</div>
<div id="resumiendo" class="section level4 hasAnchor" number="5.9.1.6">
<h4><span class="header-section-number">5.9.1.6</span> Resumiendo:<a href="estimación-puntual.html#resumiendo" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>El estimador máximo verosímil de <span class="math inline">\(\lambda\)</span> es <span class="math inline">\(\hat{\lambda} = \overline{Y}\)</span>.</li>
<li>El valor esperado de <span class="math inline">\(\hat{\lambda}\)</span> es <span class="math inline">\(E(\hat{\lambda}) = \lambda\)</span>, y su varianza es <span class="math inline">\(\text{Var}(\hat{\lambda}) = \frac{\lambda}{n}\)</span>.</li>
<li><span class="math inline">\(\hat{\lambda}\)</span> es un estimador consistente para <span class="math inline">\(\lambda\)</span>.</li>
<li>El EMV de <span class="math inline">\(P(Y = 0)\)</span> es <span class="math inline">\(\widehat{P(Y = 0)} = e^{-\overline{Y}}\)</span>.</li>
</ol>
</div>
</div>
</div>
<div id="ejercicio-10-1" class="section level2 hasAnchor" number="5.10">
<h2><span class="header-section-number">5.10</span> Ejercicio 10<a href="estimación-puntual.html#ejercicio-10-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- [W-M 80] -->
<p>Suponga que <span class="math inline">\(Y_{1}, Y_{2}, \ldots, Y_{n}\)</span> denotan una muestra aleatoria de una población distribuida exponencialmente con media <span class="math inline">\(\theta\)</span>. Encuentre el MLE de la varianza poblacional <span class="math inline">\(\theta^{2}\)</span>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="muestreo-y-distribuciones-en-el-muestreo.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="intervalos-de-confianza.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ASPteaching/FundamentosInferencia/edit/BRANCH/05-Estimacion.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ASPteaching/FundamentosInferencia-Ejercicios/blob/main/05-Estimacion.Rmd",
"text": null
},
"download": "https://github.com/ASPteaching/FundamentosInferencia-Ejercicios/blob/main/docs/_main.pdf",
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
